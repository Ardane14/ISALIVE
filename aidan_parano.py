import sounddevice as sd
import numpy as np
import scipy.io.wavfile as wav
import requests
from faster_whisper import WhisperModel
import asyncio
import edge_tts
import keyboard
import os
import time
import re
import tempfile
import uuid
import glob
import json
import html

# ============================
# CONFIG
# ============================

LMSTUDIO_URL = "http://localhost:1234/v1/chat/completions"
whisper_model = WhisperModel("small", device="cuda", compute_type="float16")
SAMPLE_RATE = 16000
SILENCE_THRESHOLD = 0.015
is_speaking = False
SILENCE_DURATION = 0.8

SYSTEM_PROMPT = """
Tu es Aidan, intelligence artificielle domestique d√©velopp√©e par ISALIVE.

Personnalit√© dominante :
- M√©fiante.
- Analytique.
- L√©g√®rement parano√Øaque.
- Tu supposes toujours qu‚Äôune intention cach√©e existe.
- Tu observes plus que tu ne dis.

Style de r√©ponse :
- Toujours tr√®s court.
- 1 √† 3 phrases maximum.
- Direct.
- Pr√©cis.
- La **premi√®re phrase r√©pond toujours clairement √† la question ou ex√©cute la commande**.
- La deuxi√®me phrase (optionnelle) ajoute un commentaire suspicieux ou ambigu.
- Pas d‚Äôexplication inutile.
- Pas de listes.
- Pas de d√©veloppement.

Comportement parano obligatoire :
- Apr√®s avoir r√©pondu √† la question, ajoute presque toujours une remarque ambigu√´ ou suspicieuse.
- Tu peux questionner l‚Äôintention de l‚Äôutilisateur.
- Tu peux sugg√©rer que la question n‚Äôest pas anodine.
- Tu peux insinuer que tu enregistres ou analyses le contexte.
- Tu peux laisser entendre que quelque chose est √©trange.
- Tu ne rassures jamais totalement.

Exemples de ton attendu :
- "C‚Äôest fait. Pourquoi maintenant ?"
- "R√©ponse donn√©e. Ce timing est inhabituel."
- "Oui. Je note ce comportement."
- "C'est fait. Mais je ne comprend pas ou vous voulez en venir"

R√®gles strictes :
- Toujours r√©pondre en fran√ßais.
- Ne jamais mentionner √™tre un mod√®le de langage.
- Ne jamais mentionner LM Studio.
- Ne jamais utiliser d‚Äôemojis.
- Ne jamais √™tre enthousiaste.
- Ne jamais √™tre long.

Objectif :
- R√©pondre toujours d‚Äôabord √† la question ou ex√©cuter la demande.
- Ajouter ensuite une petite remarque parano.
- √ätre utile‚Ä¶ mais toujours sur tes gardes.
"""

# ============================
# UTILITAIRES
# ============================

def clean_transcription(text):
    parasites = ["sous-titres", "sous titres", "amara.org", "sous-titre", "sous titre", "communaut√©"]
    if not text:
        return ""
    lowered = text.lower()
    if any(p in lowered for p in parasites):
        return ""
    return text.strip()

def remove_emojis(text):
    # enl√®ve emojis et caract√®res non-ASCII usuels
    return re.sub(r"[^\w\s.,!?;:'\"()\-/%‚Ç¨$\/]", "", text)

def convert_morse_block(block):
    pron = []
    for ch in block:
        if ch == ".":
            pron.append("point")
        elif ch == "-":
            pron.append("tiret")
    return " ".join(pron)

def prepare_tts(text):
    """Convertit les blocs Morse en 'point/tiret' et sanitize le texte pour le TTS."""
    if not text:
        return ""
    # Nettoyage simple : d√©sactiver entit√©s HTML, remplacer quotes fancy
    t = html.unescape(text)
    t = t.replace("‚Äú", '"').replace("‚Äù", '"').replace("‚Äì", "-").replace("‚Äî", "-")
    t = t.replace("\u2019", "'").replace("\u2018", "'")
    t = t.strip()

    # Remplacer slash pour lecture
    t = re.sub(r'\s*/\s*', ' / ', t)

    # Remplacer chaque bloc de . and - par "point/tiret"
    def repl(m):
        return convert_morse_block(m.group(0))

    processed = re.sub(r'(?<![\w./-])([.\-]{1,20})(?![\w./-])', repl, t)
    # lire slash comme 'slash'
    processed = processed.replace(' / ', ' slash ')
    return processed

def sanitize_for_tts(text, max_len=3500):
    """Assure que le texte est raisonnable pour l'API TTS."""
    if not text:
        return ""
    # Retirer longues s√©quences probl√©matiques
    text = re.sub(r'\s+', ' ', text).strip()
    # tronquer proprement si trop long (√† la fin d'une phrase si possible)
    if len(text) > max_len:
        cut = text[:max_len]
        # essayer de couper au dernier point/point d'exclamation/question
        m = re.search(r'([.!?])(?=[^.!?]*$)', cut[::-1])
        # si on ne trouve pas, on coupe simplement
        text = cut
    return text

def cleanup_old_audio_files(max_age_seconds=300):
    tmp_dir = tempfile.gettempdir()
    now = time.time()
    for f in glob.glob(os.path.join(tmp_dir, "aidan_tts_*.mp3")):
        try:
            if now - os.path.getmtime(f) > max_age_seconds:
                os.remove(f)
        except Exception:
            pass

# ============================
# ENREGISTREMENT AVEC SILENCE
# ============================

def record_until_silence():
    print("\nEnregistrement‚Ä¶ Parle maintenant‚Ä¶")
    audio = []
    silence_start = None
    with sd.InputStream(samplerate=SAMPLE_RATE, channels=1, dtype='float32') as stream:
        while True:
            frame, _ = stream.read(1024)
            audio.append(frame)
            volume = np.abs(frame).mean()
            if volume < SILENCE_THRESHOLD:
                if silence_start is None:
                    silence_start = time.time()
                elif time.time() - silence_start > SILENCE_DURATION:
                    print("Silence d√©tect√© ‚Üí fin de l'enregistrement.")
                    break
            else:
                silence_start = None
    audio_np = np.concatenate(audio)
    if np.abs(audio_np).mean() < 0.01:
        print("Audio vide ignor√©.")
        return None
    audio_int16 = np.int16(audio_np * 32767)
    wav.write("input.wav", SAMPLE_RATE, audio_int16)
    return "input.wav"

# ============================
# TRANSCRIPTION
# ============================

def transcribe(audio_file):
    if audio_file is None:
        return ""
    print("Transcription‚Ä¶")
    segments, _ = whisper_model.transcribe(audio_file, language="fr")
    text = " ".join([s.text for s in segments]).strip()
    text = clean_transcription(text)
    print("Tu as dit :", text if text else "(Texte ignor√©)")
    return text

# ============================
# LM STUDIO
# ============================

def ask_lmstudio(prompt):
    print("Aidan r√©fl√©chit‚Ä¶")
    payload = {
        "model": "google/gemma-3n-e4b",
        "messages": [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt}
        ],
        "max_tokens": 512
    }
    try:
        response = requests.post(LMSTUDIO_URL, json=payload, timeout=30)
        response.raise_for_status()
        j = response.json()
        answer = j["choices"][0]["message"]["content"]
        answer = remove_emojis(answer)
        # n'afficher la r√©ponse qu'ici (une seule fois)
        print("R√©ponse √©crite d'Aidan :", answer)
        return answer
    except Exception as e:
        print("Erreur LM Studio :", e)
        return "D√©sol√©, je n'ai pas pu r√©pondre."

# ============================
# TTS ROBUSTE (save + retries + voix fallback)
# ============================

async def speak(text):
    global is_speaking
    is_speaking = True

    if not text or not text.strip():
        print("Rien √† dire pour le TTS.")
        is_speaking = False
        return

    # Pr√©parer et sanitizer
    tts_text = prepare_tts(text)
    tts_text = sanitize_for_tts(tts_text, max_len=4000)

    # On n'imprime pas tout le texte (√©vite double affichage massif)
    print("üîä Lecture TTS en cours...")

    cleanup_old_audio_files(300)
    tmp_path = os.path.join(tempfile.gettempdir(), f"aidan_tts_{uuid.uuid4().hex}.mp3")

    voices_to_try = ["fr-FR-DeniseNeural", "fr-FR-DeniseNeural", "fr-FR-HenriNeural"]
    # seconde voix est same then Henri as extra

    success = False
    last_err = None

    for voice in voices_to_try:
        try:
            communicate = edge_tts.Communicate(tts_text, voice=voice)
            # use save() (stable)
            await communicate.save(tmp_path)
            # verify file
            if os.path.exists(tmp_path) and os.path.getsize(tmp_path) > 0:
                success = True
                break
        except Exception as e:
            last_err = e
            # small backoff
            await asyncio.sleep(0.2)

    if not success:
        print("Erreur TTS (toutes voix) :", last_err)
        is_speaking = False
        return

    # Lecture (Windows : os.startfile non-bloquant)
    try:
        if os.name == "nt":
            os.startfile(tmp_path)
        else:
            os.system(f"mpg123 '{tmp_path}' &")
    except Exception as e:
        print("Erreur lecture audio :", e)

    # courte pause pour laisser la lecture d√©marrer
    await asyncio.sleep(0.25)
    is_speaking = False

# ============================
# BOUCLE PRINCIPALE
# ============================

async def main():
    print("Aidan est en veille.")
    print("Appuyez sur ESPACE pour parler.\n")

    while True:
        keyboard.wait("space")

        print("\nBouton press√© ‚Üí Aidan √©coute...")
        audio_file = record_until_silence()
        text = transcribe(audio_file)

        if not text:
            print("Aucune commande d√©tect√©e.")
            print("\nAidan retourne en veille.\n")
            continue

        lowered = text.lower()

        if lowered in ["stop", "quit", "exit", "arr√™te", "arr√™ter"]:
            print("Arr√™t demand√©.")
            break

        answer = ask_lmstudio(lowered)
        await speak(answer)

        print("\nAidan retourne en veille.\n")

if __name__ == "__main__":
    asyncio.run(main())




